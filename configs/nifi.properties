# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Core Properties #
nifi.flow.configuration.file=../data/flow.xml.gz
nifi.flow.configuration.archive.enabled=true
nifi.flow.configuration.archive.dir=../data/archive/
nifi.flow.configuration.archive.max.time=30 days
nifi.flow.configuration.archive.max.storage=500 MB
nifi.flow.configuration.archive.max.count=10
nifi.flowcontroller.autoResumeState=true
nifi.flowcontroller.graceful.shutdown.period=10 sec
nifi.flowservice.writedelay.interval=500 ms
nifi.administrative.yield.duration=30 sec
# If a component has no work to do (is "bored"), how long should we wait before checking again for work? (Default 10ms)
nifi.bored.yield.duration=100 ms

nifi.authorizer.configuration.file=./conf/authorizers.xml
nifi.login.identity.provider.configuration.file=./conf/login-identity-providers.xml
nifi.templates.directory=../data/templates
nifi.ui.banner.text=
nifi.ui.autorefresh.interval=20 sec
nifi.nar.library.directory=./lib
nifi.nar.library.directory.custom={{ .Values.properties.customLibPath }}
nifi.nar.library.autoload.directory=./extensions
nifi.nar.working.directory=./work/nar/
nifi.documentation.working.directory=./work/docs/components

####################
# State Management #
####################
nifi.state.management.configuration.file=./conf/state-management.xml
# The ID of the local state provider
nifi.state.management.provider.local=local-provider
# The ID of the cluster-wide state provider. This will be ignored if NiFi is not clustered but must be populated if running in a cluster.
nifi.state.management.provider.cluster=zk-provider
# Specifies whether or not this instance of NiFi should run an embedded ZooKeeper server
nifi.state.management.embedded.zookeeper.start=false
# Properties file that provides the ZooKeeper properties to use if <nifi.state.management.embedded.zookeeper.start> is set to true
nifi.state.management.embedded.zookeeper.properties=./conf/zookeeper.properties

# H2 Settings
nifi.database.directory=../data/database_repository
nifi.h2.url.append=;LOCK_TIMEOUT=25000;WRITE_DELAY=0;AUTO_SERVER=FALSE

# FlowFile Repository
nifi.flowfile.repository.implementation=org.apache.nifi.controller.repository.WriteAheadFlowFileRepository
nifi.flowfile.repository.directory=../flowfile_repository
nifi.flowfile.repository.partitions=256
nifi.flowfile.repository.checkpoint.interval=2 mins
nifi.flowfile.repository.always.sync=false

# Swap to disk after buffers exceed swap threshold
nifi.swap.manager.implementation=org.apache.nifi.controller.FileSystemSwapManager
nifi.queue.swap.threshold=20000
nifi.swap.in.period=5 sec
nifi.swap.in.threads=1
nifi.swap.out.period=5 sec
nifi.swap.out.threads=4

# Default queue properties
nifi.queue.backpressure.count=1000
nifi.queue.backpressure.size=100 MB

# Content Repository
nifi.content.repository.implementation=org.apache.nifi.controller.repository.FileSystemRepository
nifi.content.claim.max.appendable.size=1 MB
nifi.content.claim.max.flow.files=1000
nifi.content.repository.directory.default=../content_repository
nifi.content.repository.always.sync=false
nifi.content.viewer.url=/nifi-content-viewer/

## Content Repostiroy Archive
nifi.content.repository.archive.enabled=true
nifi.content.repository.archive.max.retention.period=1 day
nifi.content.repository.archive.max.usage.percentage=85%
nifi.content.repository.archive.cleanup.frequency=10 min

# Provenance Repository Properties
nifi.provenance.repository.implementation=org.apache.nifi.provenance.WriteAheadProvenanceRepository
## Encrypted Provenance Repository Properties
nifi.provenance.repository.debug.frequency=1000000
nifi.provenance.repository.encryption.key.provider.implementation=
nifi.provenance.repository.encryption.key.provider.location=
nifi.provenance.repository.encryption.key.id=
nifi.provenance.repository.encryption.key=

# Persistent Provenance Repository Properties
nifi.provenance.repository.directory.default=../provenance_repository
# The maximum amount of data provenance information to store at a time. The default value is 10 GB.
{{- $provenanceSizeNum := mustRegexReplaceAll "([0-9]+).*$" .Values.persistence.provenanceRepoStorage.size "${1}" | int }}
{{- $provenanceSizeOrder := mustRegexReplaceAll ".*([KMGT])i?.*$" .Values.persistence.provenanceRepoStorage.size "${1}B" }}
nifi.provenance.repository.max.storage.size={{ $provenanceSizeNum }} {{ $provenanceSizeOrder }}
# The maximum amount of time to keep data provenance information. The default value is 30 days.
nifi.provenance.repository.max.storage.time=7 days
# The amount of time to wait before rolling over the "event file" that the repository is writing to.
nifi.provenance.repository.rollover.time=10 mins
# The amount of information to roll over at a time. The default value is 100 MB.
nifi.provenance.repository.rollover.size=1 GB
# The number of threads to use for Provenance Repository queries. The default value is 2.
nifi.provenance.repository.query.threads=4
# The number of threads to use for indexing Provenance events so that they are searchable. The default value is 2. For flows that operate on a very high number of FlowFiles, the indexing of Provenance events could become a bottleneck. If this is the case, a bulletin will appear, indicating that "The rate of the dataflow is exceeding the provenance recording rate. Slowing down flow to accommodate." If this happens, increasing the value of this property may increase the rate at which the Provenance Repository is able to process these records, resulting in better overall throughput.
nifi.provenance.repository.index.threads=8
# Indicates whether to compress the provenance information when rolling it over. The default value is true.
nifi.provenance.repository.compress.on.rollover=true
# If set to true, any change to the repository will be synchronized to the disk, meaning that NiFi will ask the operating system not to cache the information. This is very expensive and can significantly reduce NiFi performance. However, if it is false, there could be the potential for data loss if either there is a sudden power loss or the operating system crashes. The default value is false.
nifi.provenance.repository.always.sync=false
# The number of journal files that should be used to serialize Provenance Event data. Increasing this value will allow more tasks to simultaneously update the repository but will result in more expensive merging of the journal files later. This value should ideally be equal to the number of threads that are expected to update the repository simultaneously, but 16 tends to work well in must environments. The default value is 16.
nifi.provenance.repository.journal.count=16

# Comma-separated list of fields. Fields that are not indexed will not be searchable. Valid fields are:
# EventType, FlowFileUUID, Filename, TransitURI, ProcessorID, AlternateIdentifierURI, Relationship, Details
nifi.provenance.repository.indexed.fields=EventType, FlowFileUUID, Filename, ProcessorID, Relationship
# FlowFile Attributes that should be indexed and made searchable.  Some examples to consider are filename, uuid, mime.type
nifi.provenance.repository.indexed.attributes=filename, uuid
# Large values for the shard size will result in more Java heap usage when searching the Provenance Repository but should provide better performance. For production environments, it is advisable to change this value to 4-8 GB. Once all Provenance Events in the index have been aged off from the "event files," the index will be destroyed as well.
# NOTE: This value should be smaller than (no more than half of) the nifi.provenance.repository.max.storage.size property.
# nifi.provenance.repository.max.storage.size property
nifi.provenance.repository.index.shard.size={{ div $provenanceSizeNum 2 }} {{ $provenanceSizeOrder }}
# Indicates the maximum length that a FlowFile attribute can be when retrieving a Provenance Event from
# the repository. If the length of any attribute exceeds this value, it will be truncated when the event is retrieved.
nifi.provenance.repository.max.attribute.length=65536
# Apache Lucene creates several "segments" in an Index. These segments are periodically merged together in order to
# provide faster querying. This property specifies the maximum number of threads that are allowed to be used for each
# of the storage directories. The default value is 2. For high throughput environments, it is advisable to set the number
# of index threads larger than the number of merge threads * the number of storage locations.
# For example, if there are 2 storage locations and the number of index threads is set to 8, then the number of merge
# threads should likely be less than 4. While it is not critical that this be done, setting the number of merge threads
# larger than this can result in all index threads being used to merge, which would cause the NiFi flow to periodically
# pause while indexing is happening, resulting in some data being processed with much higher latency than other data.
nifi.provenance.repository.concurrent.merge.threads=4

# Volatile Provenance Respository Properties
nifi.provenance.repository.buffer.size=100000

# Component Status Repository
nifi.components.status.repository.implementation=org.apache.nifi.controller.status.history.VolatileComponentStatusRepository
nifi.components.status.repository.buffer.size=1440
nifi.components.status.snapshot.frequency=1 min

# Site to Site properties
nifi.remote.input.host=
nifi.remote.input.secure=true
{{- if and .Values.properties.siteToSite.enabled .Values.properties.siteToSite.port }}
nifi.remote.input.socket.port={{ .Values.properties.siteToSite.port }}
{{- end }}
nifi.remote.input.http.enabled=true
nifi.remote.input.http.transaction.ttl=60 sec
nifi.remote.contents.cache.expiration=30 mins

# web properties #
nifi.web.war.directory=./lib
nifi.web.http.host=
# Only enable http/1.1 to avoid TLS session re-use across subdomains
nifi.web.https.application.protocols=http/1.1
nifi.web.https.host=
nifi.web.https.network.interface.default=eth0
nifi.web.https.network.interface.lo=lo
nifi.web.https.port.forwarding={{ .Values.properties.httpsPortForwarding }}
nifi.web.https.port={{ .Values.properties.httpsPort }}
nifi.web.proxy.host={{ include "apache-nifi.webProxyHost" . }}
nifi.web.jetty.working.directory=./work/jetty
nifi.web.jetty.threads=200
# The request timeout for web requests. Requests running longer than this time will be forced to end with a HTTP 503 Service Unavailable response. Default value is 60 secs.
nifi.web.request.timeout=60 secs
# Whether the Server header should be included in HTTP responses. The default value is true
nifi.web.should.send.server.version=false
# nifi.web.proxy.context.path=

# security properties #
nifi.sensitive.props.key={{ .Values.properties.sensitiveKey }}
nifi.sensitive.props.key.protected=
nifi.sensitive.props.algorithm={{ .Values.properties.algorithm }}
nifi.sensitive.props.provider=BC
nifi.sensitive.props.additional.keys=

nifi.security.keystore={{ .Values.auth.SSL.keystorePath }}
nifi.security.keystoreType={{ .Values.auth.SSL.keystoreType }}
nifi.security.keystorePasswd={{ .Values.auth.SSL.keystorePasswd }}
nifi.security.keyPasswd={{ .Values.auth.SSL.keystorePasswd }}
nifi.security.truststore={{ .Values.auth.SSL.truststorePath }}
nifi.security.truststoreType={{ .Values.auth.SSL.truststoreType }}
nifi.security.truststorePasswd={{ .Values.auth.SSL.truststorePasswd }}

{{if .Values.auth.clientAuth.enabled}}
nifi.security.user.authorizer=managed-authorizer
nifi.security.user.login.identity.provider=
{{else if .Values.auth.oidc.enabled}}
nifi.security.user.authorizer=managed-authorizer
{{ else }}
nifi.security.user.login.identity.provider=single-user-provider
nifi.security.user.authorizer=single-user-authorizer
{{end}}

# Whether to auto-reload the keystore/truststore
nifi.security.autoreload.enabled=true
nifi.security.autoreload.interval=120 secs

nifi.security.needClientAuth={{ .Values.properties.needClientAuth }}

{{if .Values.auth.oidc.enabled}}
# OpenId Connect SSO Properties #
nifi.security.user.oidc.discovery.url={{ .Values.auth.oidc.discoveryUrl }}
nifi.security.user.oidc.connect.timeout=5 secs
nifi.security.user.oidc.read.timeout=5 secs
nifi.security.user.oidc.client.id={{ .Values.auth.oidc.clientId }}
nifi.security.user.oidc.client.secret={{ .Values.auth.oidc.clientSecret }}
nifi.security.user.oidc.preferred.jwsalgorithm={{ .Values.auth.oidc.preferredJwsAlgorithm }}
nifi.security.user.oidc.claim.identifying.user={{ .Values.auth.oidc.claimIdentifyingUser }}
nifi.security.user.oidc.additional.scopes={{ .Values.auth.oidc.additionalScopes }}
{{end}}

# Apache Knox SSO Properties #
nifi.security.user.knox.url=
nifi.security.user.knox.publicKey=
nifi.security.user.knox.cookieName=hadoop-jwt
nifi.security.user.knox.audiences=

# Identity Mapping Properties #
# These properties allow normalizing user identities such that identities coming from different identity providers
# (certificates, LDAP, Kerberos) can be treated the same internally in NiFi. The following example demonstrates normalizing
# DNs from certificates and principals from Kerberos into a common identity string:
#
# nifi.security.identity.mapping.pattern.dn=^CN=(.*?), OU=(.*?), O=(.*?), L=(.*?), ST=(.*?), C=(.*?)$
# nifi.security.identity.mapping.value.dn=$1@$2
# nifi.security.identity.mapping.pattern.kerb=^(.*?)/instance@(.*?)$
# nifi.security.identity.mapping.value.kerb=$1@$2

# Cluster common properties (all nodes must have same values)
# Default 5 sec
nifi.cluster.protocol.heartbeat.interval=20 sec
nifi.cluster.protocol.is.secure=true
nifi.cluster.firewall.file=

# cluster node properties (only configure for cluster nodes) #
nifi.cluster.is.node={{ .Values.properties.isNode }}
nifi.cluster.flow.election.max.candidates={{ div .Values.replicas 2 | add 1 }}
# Specifies the amount of time to wait before electing a Flow as the "correct" Flow. If the number of Nodes that have voted is equal to the number specified by the nifi.cluster.flow.election.max.candidates property, the cluster will not wait this long. The default value is 5 mins. Note that the time starts as soon as the first vote is cast.
nifi.cluster.flow.election.max.wait.time=2 mins
# The maximum number of connections to create between this node and each other node in the cluster. For example, if there are 5 nodes in the cluster and this value is set to 4, there will be up to 20 socket connections established for load-balancing purposes (5 x 4 = 20). The default value is 1.
nifi.cluster.load.balance.connections.per.node={{ .Values.properties.loadBalance.connectionsPerNode }}
nifi.cluster.load.balance.host=
# The maximum number of threads to use for transferring data from this node to other nodes in the cluster. While a given thread can only write to a single socket at a time, a single thread is capable of servicing multiple connections simultaneously because a given connection may not be available for reading/writing at any given time. The default value is 8—i.e., up to 8 threads will be responsible for transferring data to other nodes, regardless of how many nodes are in the cluster.
# Set to nifi.cluster.load.balance.connections.per.node * replicas
nifi.cluster.load.balance.max.thread.count={{ mul .Values.replicas .Values.properties.loadBalance.connectionsPerNode }}
nifi.cluster.load.balance.port={{ .Values.properties.loadBalance.port }}
nifi.cluster.node.address=
# Default 5 sec
nifi.cluster.node.connection.timeout=30 sec
nifi.cluster.node.event.history.size=25
# The maximum number of outstanding web requests that can be replicated to nodes in the cluster. If this number of requests is exceeded, the embedded Jetty server will return a "409: Conflict" response. This property defaults to 100.
nifi.cluster.node.max.concurrent.requests=200
# The maximum number of threads that should be used to communicate with other nodes in the cluster. This property defaults to 50.
# When a request is made to one node, it must be forwarded to the coordinator. The coordinator then replicates it to all nodes. There could be up to n+2 threads for a given request, where n = number of nodes in your cluster. As an example, if 4 requests are made, a 5 node cluster will use 4 * 7 = 28 threads.
nifi.cluster.node.protocol.max.threads=100
nifi.cluster.node.protocol.port={{ .Values.properties.clusterPort }}
nifi.cluster.node.protocol.threads=10
# Default 5 sec
nifi.cluster.node.read.timeout=30 sec

# Analytics properties
# This indicates whether prediction should be enabled for the cluster. The default is false.
nifi.analytics.predict.enabled=true
# The time interval for which analytical predictions (e.g. queue saturation) should be made. The default value is 3 mins.
nifi.analytics.predict.interval=3 mins
# The time interval to query for past observations (e.g. the last 3 minutes of snapshots). The default value is 5 mins. NOTE: This value should be at least 3 times greater than nifi.components.status.snapshot.frequency to ensure enough observations are retrieved for predictions.
nifi.analytics.query.interval=5 mins

# Runtime Monitoring Properties
# The time period between successive executions of the Long-Running Task Monitor (e.g. 1 min).
nifi.monitor.long.running.task.schedule=3 mins
# The time period beyond which a task is considered long-running, i.e. stuck / hanging (e.g. 5 mins).
nifi.monitor.long.running.task.threshold=10 mins
# The nifi.performance.tracking.percentage property can be used to enable the tracking of additional metrics. Gathering these metrics, however, require system calls, which can be expensive on some systems. As a result, this property defaults to a value of 0, indicating that the metrics should be captured 0% of the time. I.e., the feature is disabled by default. To enable this feature, set the value of this property to an integer value in the range of 0 to 100, inclusive. This represents what percentage of the time NiFi should gather these metrics.
# nifi.performance.tracking.percentage=20
# NiFi can be configured to automatically execute the diagnostics command in the event of a shutdown. The feature is disabled by default and can be enabled with the nifi.diagnostics.on.shutdown.enabled property in the nifi.properties configuration file. It is also possible to configure where the files should be stored and how many files should be kept using the below properties
nifi.diagnostics.on.shutdown.directory=../data/diagnostics
nifi.diagnostics.on.shutdown.max.filecount=10
nifi.diagnostics.on.shutdown.max.directory.size=10 MB

# zookeeper properties, used for cluster management #
nifi.zookeeper.connect.string={{ template "zookeeper.url" . }}
nifi.zookeeper.connect.timeout=3 secs
nifi.zookeeper.session.timeout=3 secs
nifi.zookeeper.root.node=/nifi

# Zookeeper properties for the authentication scheme used when creating acls on znodes used for cluster management
# Values supported for nifi.zookeeper.auth.type are "default", which will apply world/anyone rights on znodes
# and "sasl" which will give rights to the sasl/kerberos identity used to authenticate the nifi node
# The identity is determined using the value in nifi.kerberos.service.principal and the removeHostFromPrincipal
# and removeRealmFromPrincipal values (which should align with the kerberos.removeHostFromPrincipal and kerberos.removeRealmFromPrincipal
# values configured on the zookeeper server).
nifi.zookeeper.auth.type=
nifi.zookeeper.kerberos.removeHostFromPrincipal=
nifi.zookeeper.kerberos.removeRealmFromPrincipal=

# kerberos #
nifi.kerberos.krb5.file=

# kerberos service principal #
nifi.kerberos.service.principal=
nifi.kerberos.service.keytab.location=

# kerberos spnego principal #
nifi.kerberos.spnego.principal=
nifi.kerberos.spnego.keytab.location=
nifi.kerberos.spnego.authentication.expiration=12 hours

# external properties files for variable registry
# supports a comma delimited list of file locations
nifi.variable.registry.properties=

{{- $httpsExternalPort := int (.Values.properties.httpsPortForwarding | default .Values.properties.httpsPort) -}}
{{- $replicas := int .Values.replicas }}
{{- $hostCount := int (.Values.properties.siteToSite.hostCount | default $replicas) }}

{{- if .Values.properties.siteToSite.hostCount }}
# Custom routing rules to expose fewer nodes externally
nifi.remote.route.http.external.hostname=node${s2s.target.hostname:replaceFirst('node([0-9]+)-.*', '$1'):toNumber():mod({{ $hostCount }})}-{{ $.Values.clusterName }}
nifi.remote.route.http.external.when=true
nifi.remote.route.http.external.port=${X-ProxyHost:isNull():ifElse("8443","443")}
nifi.remote.route.http.external.secure=true
{{- end }}
